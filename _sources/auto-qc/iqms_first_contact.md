---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

```{code-cell} python
:tags: [remove-cell]
import matplotlib as mpl
mpl.rcParams['font.family'] = "Libre Franklin"
```

# Understanding IQMs generated by MRIQC

The `mriqc-learn` package comes with some example data for users, derived from the MRIQC paper.
First, we will be using a dataset containing IQMs generated on the open-access ABIDE I dataset which contains manual assessments by human raters.
Let's explore the dataset:

```{code-cell} python
# 1. mriqc-learn comes with a convenience data loader, you'll need to first import it.
from mriqc_learn.datasets import load_dataset

# 2. Once imported, let's pull up some data
(train_x, train_y), _ = load_dataset(split_strategy="none")
```

With the argument `split_strategy="none"` we are indicating that we want to obtain the full dataset, without partitioning it in any ways.
That means variable `train_x` will contain *features* (in other words, the actual IQMs) and `train_y` contains manual assessments, for 1101 T1-weighted MRI images of ABIDE I.
Both data tables `train_x` and `train_y` have the structure of Pandas DataFrames.

In order to investigate those "site-effects", let's add a column to `train_x` with site information:

```{code-cell} python
train_x["site"] = train_y.site
```

These sites correspond to the following acquisition parameters:

<img src="https://journals.plos.org/plosone/article/figure/image?size=large&download=&id=10.1371/journal.pone.0184661.t001" />

## A first look on the dataset
Lets now have a first quick look over the data:

```{code-cell} python
train_x
```

This first look is not very informative - there's no way we can pick any of the structure in our dataset.
Let's make use of one plotting utility of `mriqc-learn`, and observe the structure:

```{code-cell} python
# 1. Let's import a module containing visualization tools for IQMs
from mriqc_learn.viz import metrics

# 2. Plot the dataset
fig1 = metrics.plot_batches(train_x)
```

The plot above is clearly blocky, very well aligned with the different acquisition sites that are comprehended.

## Homogenizing across sites

One first thought to make these IQMs more homogeneous would be to site-wise standardize them.
This means, for each site, calculate mean and standard deviation and apply them to convert IQMs to zero-mean, unit-variance distributions.
`mriqc-learn` has a filter (derived from, and compatible with `scikit-learn`) to do this:

```{code-cell} python
# Load the filter
from mriqc_learn.models.preprocess import SiteRobustScaler

# Plot data after standardization
standardized_x = SiteRobustScaler(unit_variance=True).fit_transform(train_x)
fig2 = metrics.plot_batches(standardized_x)
```

Now the plot is not so *blocky*.
The problem of using data that is not harmonized is that any model we train on those features heavily reliant on the site of acquisition will be better at picking up the site where the image was acquired rather than the quality.
This is so because perceived image quality by humans is very correlated with the site of acquisition.
In other words, our machine-learning model will operate like a human would do: *given that this site produces mostly poor images, I will assume all images coming from it are poor*.


## Manual ratings are very correlated with the acquisition site
Let's go further in exploring this effect, by now focusing our attention on the dataset targets (`train_y`).

