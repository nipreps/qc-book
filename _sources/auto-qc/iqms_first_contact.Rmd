---
jupyter:
  jupytext:
    notebook_metadata_filter: all,-language_info
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
:tags: [remove-cell]
import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rcParams["font.family"] = "Libre Franklin"
plt.rcParams["axes.facecolor"] = "white"
plt.rcParams["savefig.facecolor"] = "white"
```

# Understanding IQMs generated by MRIQC

The `mriqc-learn` package comes with some example data for users, derived from the MRIQC paper.
First, we will be using a dataset containing IQMs generated on the open-access ABIDE I dataset which contains manual assessments by human raters.
Let's explore the dataset:

```{python}
# 1. mriqc-learn comes with a convenience data loader, you'll need to first import it.
from mriqc_learn.datasets import load_dataset

# 2. Once imported, let's pull up some data
(train_x, train_y), _ = load_dataset(split_strategy="none")
```

With the argument `split_strategy="none"` we are indicating that we want to obtain the full dataset, without partitioning it in any ways.
That means variable `train_x` will contain *features* (in other words, the actual IQMs) and `train_y` contains manual assessments, for 1101 T1-weighted MRI images of ABIDE I.
Both data tables `train_x` and `train_y` have the structure of Pandas DataFrames.

In order to investigate those "site-effects", let's add a column to `train_x` with site information:

```{python}
train_x["site"] = train_y.site
```

These sites correspond to the following acquisition parameters:

<img src="https://journals.plos.org/plosone/article/figure/image?size=large&download=&id=10.1371/journal.pone.0184661.t001" />

## A first look on the dataset
Lets now have a first quick look over the data:

```{python}
train_x
```

This first look is not very informative - there's no way we can pick any of the structure in our dataset.
Let's make use of one plotting utility of `mriqc-learn`, and observe the structure:

```{python}
# 1. Let's import a module containing visualization tools for IQMs
from mriqc_learn.viz import metrics

# 2. Plot the dataset
fig1 = metrics.plot_batches(train_x)
```

The plot above is clearly blocky, very well aligned with the different acquisition sites that are comprehended.

## Homogenizing across sites

One first thought to make these IQMs more homogeneous would be to site-wise standardize them.
This means, for each site, calculate mean and standard deviation and apply them to convert IQMs to zero-mean, unit-variance distributions.
`mriqc-learn` has a filter (derived from, and compatible with `scikit-learn`) to do this:

```{python}
# Load the filter
from mriqc_learn.models.preprocess import SiteRobustScaler

# Plot data after standardization
standardized_x = SiteRobustScaler(unit_variance=True).fit_transform(train_x)
fig2 = metrics.plot_batches(standardized_x)
```

Now the plot is not so *blocky*.

A different way of looking at this is plotting histograms of some metrics, with the original and the standardized version represented side-by-side.
For example, this would be the picture for the coefficient of joint variation (CJV), which is passed in as the `metric` argument:

```{python}
metrics.plot_histogram(train_x, standardized_x, metric="cjv");
```

It is clear that, on the left, sites tend to cluster in regions of the spread of values (*X*-axis).
Conversely, on the right-hand histogram, sites overlap much more and form together some sort of gaussian distribution.

The situation is even more clear for the following definition of SNR (`snrd_total`):
```{python}
metrics.plot_histogram(train_x, standardized_x, metric="snrd_total");
```

Now, this is how the *entropy-focus criterion* (EFC) looks like:
```{python}
metrics.plot_histogram(train_x, standardized_x, metric="efc");
```

Finally, a look on a very commonly used parameter, the *contrast-to-noise ratio* (CNR):
```{python}
metrics.plot_histogram(train_x, standardized_x, metric="cnr");
```

```{admonition} What's the problem?
Any model we train on those features heavily reliant on the site of acquisition will rather pick up the site where the image was acquired than the quality (which is our target).
This is so because perceived image quality by humans (the target outcome we want to predict) is very correlated with the site of acquisition.
In other words, our machine-learning model will operate like a human would do: *given that this site produces mostly poor images, I will assume all images coming from it are poor*.
```

At this point, it is clear that we are about to try training models on rather noisy features, which also show strong biases correlated with the acquisition site.

Unfortunately, there are further complications.
Indeed, the targets (image quality assessments) that we can use in training are also very noisy, as we will see in the next unit.
